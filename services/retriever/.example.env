POSTGRES_USER=postgres # pragma: allowlist secret
POSTGRES_PASSWORD=yourpassword # pragma: allowlist secret
POSTGRES_DB=yourdb # pragma: allowlist secret
POSTGRES_PORT=5432 # pragma: allowlist secret
POSTGRES_HOST=dbhost # pragma: allowlist secret
POSTGRES_URL=postgresql+asyncpg://postgres:yourpassword@dbhost:5432/yourdb # pragma: allowlist secret

LLM_PROVIDER= provider_name # openai or anthropic, gemini, ollama
LLM_MODEL= model_name # Must match the provider you chose
LLM_TEMPERATURE= # 0.0 = deterministic, 1.0 = creative

OPENAI_API_KEY=your-openai-key  # pragma: allowlist secret
ANTHROPIC_API_KEY=your-anthropic-key  # pragma: allowlist secret
GEMINI_API_KEY=your-gemini-key  # pragma: allowlist secret
OLLAMA_BASE_URL=http://localhost:11434  # example of use: > curl -fsSL https://ollama.ai/install.sh | sh > ollama run llama3.2:1b

API_URL=http://backend:8000 # for local API_URL= http://loaclhost:8000
HOST=0.0.0.0
PORT=3000


# =============================================================================
# MODEL EXAMPLES FOR DIFFERENT PROVIDERS
# =============================================================================
#
# For OpenAI (LLM_PROVIDER=openai):
#   LLM_MODEL=gpt-3.5-turbo      # Fast, cost-effective
#   LLM_MODEL=gpt-4o-mini        # Better quality, still affordable
#   LLM_MODEL=gpt-4o             # Best quality
#
# For Anthropic (LLM_PROVIDER=anthropic):
#   LLM_MODEL=claude-3-5-sonnet-20241022  # Best balance
#   LLM_MODEL=claude-3-5-haiku-20241022   # Fastest
#
# For Gemini (LLM_PROVIDER=gemini):
#   LLM_MODEL=gemini-1.5-flash   # Fast, cost-effective
#   LLM_MODEL=gemini-1.5-pro     # Best quality
#
# For Ollama (LLM_PROVIDER=ollama):
#   LLM_MODEL=llama3.2:1b        # Lightweight (1GB)
#   LLM_MODEL=llama3.2           # Standard (4GB)
#   LLM_MODEL=mistral            # Alternative
#   First run: ollama pull <model-name>
